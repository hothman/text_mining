{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "#### author Houcmeddine Othman, September 2019, [My Github page](https://github.com/hothman) \n",
    "\n",
    "The codes in this notebook are written for:\n",
    "\n",
    "* reading the data in PGKB. \n",
    "* Generating bibliography references list to be used for manual curation later. \n",
    "* Data wrangling for multiple genes and multiple drug entries\n",
    "* Parsing XML medline data.\n",
    "* In general providing clean raw data before generating the tables according to the Entity-relationship model for the database. \n",
    "\n",
    "### requirements:\n",
    "* Python 3\n",
    "* Pandas, numpy, pubmed_parser\n",
    "\n",
    "---\n",
    "## Credits\n",
    "### Without the contribution of these people, I would end up with ugly empty output files and big ERROR message. \n",
    "\n",
    "#### Manual Curation (in alphabetical order) \n",
    "Ayoub Ksouri, Chaimae SAMTAL, Chiamaka Jessica Okeke, Fouzia Radouani, Haifa Jmal, Kais Ghedira, Lyndon Zass, Melek Chaouch, Olivier, Reem Sallam, Rym Kefi, Samah Ahmed, Samar kamel Kassem, Yosr Hamdi.\n",
    "\n",
    "#### Data mining and wrangling\n",
    "Jorge da Rocha and Lyndon Zass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration of PGKB data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6375"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pheno=pd.read_csv(\"../data/annotation/var_pheno_ann.tsv\", delimiter=\"\\t\")\n",
    "drug=pd.read_csv(\"../data/annotation/var_drug_ann.csv\", delimiter=\"\\t\")\n",
    "\n",
    "pmid = pd.read_csv(\"../data/pubmed_ids_list_PGKB_09Aug2019.csv\", header=None, names=[\"PMID\"])\n",
    "\n",
    "def getPMID(dataframe): \n",
    "    return dataframe[\"PMID\"].unique() \n",
    "\n",
    "uniquePMID = getPMID(pmid)\n",
    "len(uniquePMID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data for curation (PhamGKB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will join the PMID from the text mining study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of variants in Jorge's file\t 441\n",
      "number of variants in text mining identified variants\t 222\n",
      "number of total variants\t 479\n"
     ]
    }
   ],
   "source": [
    "#read the pmid identified by text mining \n",
    "drug=pd.read_csv(\"../data/annotation/var_drug_ann.csv\", delimiter=\"\\t\")\n",
    "pmid_africans=pd.read_csv(\"../data/is_african_pharmgkb_PASS.tsv\", delimiter=\"\\t\", header=None, \n",
    "                          names=[\"PMID\", \"filter\", \"hit\"])\n",
    "# read Jorge's file\n",
    "Jorge_filtering=pd.read_csv(\"../data/Jorge_filtering/African_NorthAf_and_AF_Amer_PharmGKB_vardrug.txt\", delimiter=\"\\t\")\n",
    "print(\"number of variants in Jorge's file\\t\", len(Jorge_filtering))\n",
    "\n",
    "joined_drug=pd.merge(pmid_africans[\"PMID\"], drug, on='PMID', how='inner')\n",
    "print(\"number of variants in text mining identified variants\\t\", len(joined_drug))\n",
    "\n",
    "# merge Jorge's data and my data\n",
    "result = Jorge_filtering.append(joined_drug, sort=False)\n",
    "\n",
    "# remove duplicates based on annotation ID\n",
    "result=result.drop_duplicates(subset='Annotation ID', keep='first')\n",
    "print(\"number of total variants\\t\", len(result))\n",
    "\n",
    "result.to_csv('../data/filtered_entries_phamGKB.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract data from PharmGKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation ID           int64\n",
       "Variant                object\n",
       "Gene                   object\n",
       "Chemical               object\n",
       "PMID                    int64\n",
       "Phenotype Category     object\n",
       "Significance           object\n",
       "Notes                  object\n",
       "Sentence               object\n",
       "StudyParameters        object\n",
       "Alleles                object\n",
       "Chromosome             object\n",
       "Unnamed: 12           float64\n",
       "Unnamed: 13           float64\n",
       "Unnamed: 14           float64\n",
       "Unnamed: 15           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pgkb_data = pd.read_csv(\"../data/filtered_entries_phamGKB.csv\")\n",
    "\n",
    "pgkb_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the entries contain multiple genes per. I a; splitting them to generate the full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the entries contain many genes \n",
    "# so we need to split them\n",
    "gene_names = []\n",
    "for gene in pgkb_data[\"Gene\"]: \n",
    "    for element in ( str(gene).split()): \n",
    "        if \"(\" not in element: \n",
    "            gene_names.append(element)\n",
    "\n",
    "genes = pd.DataFrame({\"gene_name\":gene_names })\n",
    "genes.drop_duplicates(inplace=True)\n",
    "# remove contaminaiting nan as object\n",
    "genes=genes[genes.gene_name != 'nan']\n",
    "genes.to_csv(\"../data/gene_name_list.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_star_allele(dataframe): \n",
    "    mydataframe =  dataframe[[\"Variant\", \"Chemical\", \"PMID\", \"Chromosome\", \"Annotation ID\", \"Gene\"]]\n",
    "    print(mydataframe[\"Chemical\"].split(\",\")) \n",
    "\n",
    "dataframe_star = pd.DataFrame()\n",
    "star_notation, pgkb_id, gene_name, drug_name, PMID, phenotype, allele =  ([] for i in range(7))\n",
    "\n",
    "for index, variant in enumerate(pgkb_data[\"Variant\"]): \n",
    "    if \"*\" in variant :\n",
    "        splitted_star_alleles = variant.split(\",\")\n",
    "        for star_allele in splitted_star_alleles:  \n",
    "            raw= list(pgkb_data.loc[index])\n",
    "            raw[1]=star_allele\n",
    "            star_notation.append(star_allele.strip())\n",
    "            #print(raw)\n",
    "            #print(raw[9:11])\n",
    "            pgkb_id.append( raw[0] )\n",
    "            gene_name.append( raw[2].split()[0].strip() )\n",
    "            drug_name.append( raw[3].split()[0].strip() )\n",
    "            PMID.append( raw[4] )\n",
    "            phenotype.append( raw[8] )\n",
    "            allele.append( raw[10] )\n",
    "\n",
    "source=[\"PharmGKB\"]*len(star_notation)\n",
    "\n",
    "star_alleles = { \"star_annotation\": star_notation, \n",
    "        \"drug_name\": drug_name,\"gene_name\":gene_name, \n",
    "        \"phenotype\":phenotype, \"allele\":allele,  \"reference_id\":PMID, \n",
    "       \"source\":source, \"id_in_source\":pgkb_id }\n",
    "\n",
    "dataframe_star = pd.DataFrame(star_alleles)\n",
    "\n",
    "dataframe_star.to_csv(\"../data/star_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleansing of SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variants have more than one gene and are corrected based on dbsnp \n",
    "# manually \n",
    "\n",
    "\n",
    "to_correct = {\"rs9934438\":\"VKORC1\", \"rs776746\":\"CYP3A5\", \"rs17886199\":\"VKORC1\", \n",
    "             \"rs12979860\":\"IFNL4\", \"rs41303343\":\"CYP3A5\", \"rs10264272\":\"CYP3A5\", \n",
    "             \"rs776746\":\"CYP3A5\", \"rs429358\":\"APOE\", \"rs7412\":\"APOE\", \"rs12979860\":\"IFNL4\", \n",
    "              \"rs34650714\":\"UGT1A1\"}\n",
    "\n",
    "dataframe_snp = pd.DataFrame()\n",
    "rs_id, pgkb_id, gene_name, drug_name, PMID, phenotype, allele =  ([] for i in range(7))\n",
    "\n",
    "for index, variant in enumerate(pgkb_data[\"Variant\"]): \n",
    "    if \"*\" not in variant and (\"rs\" in variant): \n",
    "        raw = list(pgkb_data.loc[index])\n",
    "        \n",
    "        # correct gene names from to_correct dictionary \n",
    "        if raw[1] in to_correct.keys() : \n",
    "            raw[1] = to_correct[raw[1]]  \n",
    "        \n",
    "        # gene name but remove the second part\n",
    "        else:\n",
    "            raw[2]=str(raw[2]).split()[0]\n",
    "            \n",
    "        drugs = raw[3].split(\",\") \n",
    "        for drug in drugs :   \n",
    "            raw[3] =  drug.split()[0]\n",
    "        rs_id.append(  raw[1] )\n",
    "        pgkb_id.append(  raw[0] )\n",
    "        gene_name.append(raw[2])\n",
    "        drug_name.append( raw[3] )\n",
    "        PMID.append( raw[4] )\n",
    "        phenotype.append( raw[8] )\n",
    "        allele.append( raw[10] ) \n",
    "        \n",
    "source=[\"PharmGKB\"]*len(pgkb_id)\n",
    "       \n",
    "snps = { \"rs_id\": rs_id,  \"gene_name\":gene_name, \n",
    "        \"drug_name\": drug_name, \"phenotype\":phenotype, \"allele\":allele,  \"reference_id\":PMID, \n",
    "        \"source\":source, \"id_in_source\":pgkb_id }\n",
    "        \n",
    "dataframe_snp = pd.DataFrame(snps)\n",
    "\n",
    "dataframe_snp.replace(to_replace=\"uric\", value='uric acid', regex=True, inplace=True)\n",
    "\n",
    "dataframe_snp.to_csv(\"../data/snp_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houcemeddine/modules/anaconda/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# this list will serve me to download the medline data in xml format\n",
    "pgkb_data[\"PMID\"].drop_duplicates().to_csv(\"../data/PMIDs_pgkb_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing references table\n",
    "PMIDs are extracted to a one column csv file which was then processed by the script `construct_ref_xml.sh`. Using edirect, entries where downloaded with their xml files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubmed_parser as pp   # I need this only to get an easy access \n",
    "                            #to multiple Pubned xmls, this is just a lasy way to do it\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "path_xml = pp.list_xml_path('../data/xml_references/') # list all xml paths under directory\n",
    "\n",
    "# the function parses xml files and extract PMID, publication year and paper title\n",
    "def ParsePMEDXML(xmlfile):\n",
    "    tree = ET.parse(xmlfile) \n",
    "    root = tree.getroot()\n",
    "    PMID = tree.findall('PubmedArticle/MedlineCitation/PMID') \n",
    "    pmid = PMID[0].text\n",
    "    YEAR = tree.findall('PubmedArticle/MedlineCitation/Article/Journal/JournalIssue/PubDate/Year') \n",
    "    try:\n",
    "        year = YEAR[0].text\n",
    "    except: \n",
    "        # new articles don t have Year element under Pbdate\n",
    "        YEAR = tree.findall('PubmedArticle/MedlineCitation/DateRevised/Year') \n",
    "        year=YEAR[0].text\n",
    "    Title = tree.findall('PubmedArticle/MedlineCitation/Article/ArticleTitle') \n",
    "    title = Title[0].text\n",
    "    return pmid, year, title\n",
    "\n",
    "# iteratte over the list of xml files\n",
    "id=[]; ti = []; yy = []\n",
    "for reference_file in path_xml : \n",
    "    pmid, year, title = ParsePMEDXML(reference_file)\n",
    "    id.append(pmid)\n",
    "    yy.append(year)\n",
    "    ti.append(title)\n",
    "    \n",
    "type = len(ti)*['PMID']\n",
    "\n",
    "reference_raw = pd.DataFrame({\"external_id\":id, \"type\":type, \"year\":yy, \"title\":ti})\n",
    "\n",
    "reference_raw.to_csv(\"../data/referance_raw.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
